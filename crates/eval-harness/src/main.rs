use anyhow::{Context, Result};
use chrono::{DateTime, Utc};
use clap::Parser;
use rand::Rng;
use serde::Deserialize;
use statrs::distribution::{Binomial, DiscreteCDF};
use std::collections::BTreeMap;
use std::fs::{File, OpenOptions};
use std::io::Write;
use std::path::{Path, PathBuf};
use tokio::process::Command;

const DEFAULT_BATCH_SIZE: usize = 500;
const DEFAULT_DELTA_SAMPLE_LIMIT: usize = 200;
const MIN_ALPHA: f64 = 1e-6;
const MAX_ALPHA: f64 = 0.5;

#[derive(Deserialize, Debug)]
#[allow(dead_code)]
struct SessionRecord {
    session_id: String,
    timestamp: String,
    query: String,
    verdict: String,
    requires_manual_review: bool,
    math_status: String,
    math_alert_required: bool,
    domain_label: Option<String>,
    confidence_bucket: Option<String>,
}

#[derive(Parser, Debug)]
#[command(
    author,
    version,
    about = "Replay sessions and quantify behaviour deltas"
)]
struct Args {
    /// Path to curated JSON file generated by data-pipeline
    #[arg(long)]
    input: PathBuf,

    /// Limit replays (default: all assigned to this shard)
    #[arg(long)]
    limit: Option<usize>,

    /// Output directory
    #[arg(long, default_value = "data/eval/latest")]
    output_dir: PathBuf,

    /// Replay command tokens (e.g. --replay "cargo" --replay "run" ...)
    #[arg(
        long = "replay",
        default_values = ["cargo", "run", "--offline", "-p", "deepresearch-cli", "query", "--format", "json"]
    )]
    replay_cmd: Vec<String>,

    /// Maximum allowed verdict changes before failing (default: 0)
    #[arg(long, default_value_t = 0)]
    max_verdict_delta: usize,

    /// Maximum allowed math status changes before failing (default: usize::MAX to ignore)
    #[arg(long, default_value_t = usize::MAX)]
    max_math_delta: usize,

    /// Maximum allowed manual review diffs before failing (default: usize::MAX)
    #[arg(long, default_value_t = usize::MAX)]
    max_manual_delta: usize,

    /// Bootstrap resampling iterations (default: 1000)
    #[arg(long, default_value_t = 1_000)]
    bootstrap_samples: usize,

    /// Significance level for bootstrap confidence interval (default: 0.05, i.e. 95% CI)
    #[arg(long, default_value_t = 0.05)]
    bootstrap_alpha: f64,

    /// Total number of shards when distributing workload (default: 1)
    #[arg(long, default_value_t = 1)]
    shard_count: usize,

    /// Index of this shard (0-indexed)
    #[arg(long, default_value_t = 0)]
    shard_index: usize,

    /// Number of deltas to buffer before flushing to disk (0 disables batching)
    #[arg(long, default_value_t = DEFAULT_BATCH_SIZE)]
    batch_size: usize,

    /// Maximum number of deltas to keep inline in the report (reservoir sampled)
    #[arg(long, default_value_t = DEFAULT_DELTA_SAMPLE_LIMIT)]
    delta_sample_limit: usize,
}

#[derive(Default, Clone, serde::Serialize)]
struct AggregateMetrics {
    total_sessions: usize,
    verdict_changed: usize,
    math_status_changed: usize,
    manual_review_changed: usize,
}

#[derive(Clone, serde::Serialize)]
struct SessionDelta {
    session_id: String,
    baseline_timestamp: String,
    domain_label: Option<String>,
    confidence_bucket: Option<String>,
    verdict_before: String,
    verdict_after: String,
    math_status_before: String,
    math_status_after: String,
    manual_review_before: bool,
    manual_review_after: bool,
    verdict_changed: bool,
    math_changed: bool,
    manual_review_changed: bool,
    timestamp: DateTime<Utc>,
}

#[derive(Default, Clone, serde::Serialize)]
struct BucketReport {
    overall: AggregateMetrics,
    by_bucket: BTreeMap<String, AggregateMetrics>,
}

#[derive(Default, Clone, serde::Serialize)]
struct MetricStatistics {
    total_sessions: usize,
    changed_sessions: usize,
    proportion: f64,
    ci_lower: f64,
    ci_upper: f64,
    p_value: Option<f64>,
    threshold_configured: Option<usize>,
    threshold_proportion: Option<f64>,
}

#[derive(Default, Clone, serde::Serialize)]
struct StatisticsReport {
    verdict: MetricStatistics,
    math_status: MetricStatistics,
    manual_review: MetricStatistics,
}

#[derive(Clone, serde::Serialize)]
struct BootstrapConfig {
    samples: usize,
    alpha: f64,
    confidence: f64,
}

#[derive(Default, Clone, serde::Serialize)]
struct ShardMetadata {
    shard_index: usize,
    shard_count: usize,
    assigned_sessions: usize,
    processed_sessions: usize,
    skipped_sessions: usize,
    limit: Option<usize>,
    delta_batches_written: usize,
    delta_sample_size: usize,
    total_deltas: usize,
}

#[derive(Clone, serde::Serialize)]
struct Thresholds {
    verdict_max: Option<usize>,
    math_max: Option<usize>,
    manual_max: Option<usize>,
}

struct DashboardContext<'a> {
    report: &'a BucketReport,
    stats: &'a StatisticsReport,
    shard: &'a ShardMetadata,
    thresholds: &'a Thresholds,
    delta_sample: &'a [SessionDelta],
    bootstrap: &'a BootstrapConfig,
    delta_batch_files: &'a [String],
}

#[derive(serde::Serialize)]
struct HarnessReport {
    summary: BucketReport,
    statistics: StatisticsReport,
    bootstrap: BootstrapConfig,
    thresholds: Thresholds,
    shard: ShardMetadata,
    delta_sample_limit: usize,
    delta_sample: Vec<SessionDelta>,
    delta_batch_files: Vec<String>,
}

fn load_records(path: &PathBuf) -> Result<Vec<SessionRecord>> {
    let file = File::open(path).with_context(|| format!("open {}", path.display()))?;
    let records: Vec<SessionRecord> = serde_json::from_reader(file)
        .with_context(|| format!("parse JSON records from {}", path.display()))?;
    Ok(records)
}

struct ReplayOutcome {
    verdict: String,
    math_status: Option<String>,
    manual_review: Option<bool>,
}

async fn replay_session(cmd: &[String], query: &str) -> Result<ReplayOutcome> {
    let mut command = Command::new(&cmd[0]);
    command.args(&cmd[1..]);
    command.arg(query);
    let output = command.output().await.context("execute replay command")?;
    if !output.status.success() {
        return Err(anyhow::anyhow!(
            "replay failed: {}",
            String::from_utf8_lossy(&output.stderr)
        ));
    }
    let stdout = String::from_utf8_lossy(&output.stdout).into_owned();

    if let Ok(value) = serde_json::from_str::<serde_json::Value>(&stdout) {
        let verdict = find_string(
            &value,
            &[
                &["critique", "verdict"],
                &["report", "verdict"],
                &["verdict"],
                &["summary"],
            ],
        )
        .unwrap_or_else(|| extract_fallback(&stdout));

        let math_status = find_string(&value, &[&["math", "status"], &["math_status"]]);

        let manual_review = find_bool(
            &value,
            &[
                &["critique", "manual_review"],
                &["manual_review"],
                &["requires_manual_review"],
            ],
        );

        return Ok(ReplayOutcome {
            verdict,
            math_status,
            manual_review,
        });
    }

    Ok(ReplayOutcome {
        verdict: extract_fallback(&stdout),
        math_status: None,
        manual_review: None,
    })
}

fn extract_fallback(stdout: &str) -> String {
    stdout.lines().next().unwrap_or_default().trim().to_string()
}

fn find_string(value: &serde_json::Value, paths: &[&[&str]]) -> Option<String> {
    for path in paths {
        let mut current = value;
        for key in *path {
            current = current.get(key)?;
        }
        if let Some(s) = current.as_str() {
            return Some(s.trim().to_string());
        }
        if let Some(n) = current.as_f64() {
            return Some(n.to_string());
        }
    }
    None
}

fn find_bool(value: &serde_json::Value, paths: &[&[&str]]) -> Option<bool> {
    for path in paths {
        let mut current = value;
        for key in *path {
            current = current.get(key)?;
        }
        if let Some(b) = current.as_bool() {
            return Some(b);
        }
    }
    None
}

fn clamp_alpha(alpha: f64) -> f64 {
    alpha.clamp(MIN_ALPHA, MAX_ALPHA)
}

fn bootstrap_interval(samples: &[bool], iterations: usize, alpha: f64) -> (f64, f64) {
    if samples.is_empty() || iterations == 0 {
        return (0.0, 0.0);
    }
    let alpha = clamp_alpha(alpha);
    let n = samples.len();
    let successes: Vec<u8> = samples.iter().map(|&b| b as u8).collect();
    let mut rng = rand::thread_rng();
    let mut dist = Vec::with_capacity(iterations);
    for _ in 0..iterations {
        let mut sum = 0usize;
        for _ in 0..n {
            let idx = rng.gen_range(0..n);
            sum += successes[idx] as usize;
        }
        dist.push(sum as f64 / n as f64);
    }
    dist.sort_by(|a, b| a.partial_cmp(b).unwrap());

    let lower_idx = ((alpha / 2.0) * (iterations as f64)).floor() as usize;
    let upper_idx = ((1.0 - alpha / 2.0) * (iterations as f64)).ceil() as usize;

    let lower = dist[lower_idx.min(dist.len() - 1)];
    let upper = dist[upper_idx.min(dist.len() - 1)];
    (lower, upper)
}

fn binomial_upper_tail(total: usize, changed: usize, threshold: f64) -> f64 {
    if total == 0 {
        return 1.0;
    }
    let p = threshold.clamp(0.0, 1.0);
    if changed == 0 {
        return 1.0;
    }
    let binom = match Binomial::new(p, total as u64) {
        Ok(b) => b,
        Err(_) => return 1.0,
    };
    1.0 - binom.cdf((changed - 1) as u64)
}

fn compute_metric_statistics(
    flags: &[bool],
    threshold: usize,
    bootstrap_samples: usize,
    alpha: f64,
) -> MetricStatistics {
    let total = flags.len();
    let changed = flags.iter().filter(|&&b| b).count();
    let proportion = if total == 0 {
        0.0
    } else {
        changed as f64 / total as f64
    };
    let (ci_lower, ci_upper) = if total == 0 || bootstrap_samples == 0 {
        (0.0, 0.0)
    } else {
        bootstrap_interval(flags, bootstrap_samples, alpha)
    };

    let threshold_configured = if threshold == usize::MAX {
        None
    } else {
        Some(threshold)
    };

    let threshold_proportion = if threshold == usize::MAX || total == 0 {
        None
    } else {
        Some((threshold.min(total)) as f64 / total as f64)
    };

    let p_value = match (threshold_proportion, total) {
        (Some(prop), t) if t > 0 => Some(binomial_upper_tail(t, changed, prop)),
        _ => None,
    };

    MetricStatistics {
        total_sessions: total,
        changed_sessions: changed,
        proportion,
        ci_lower,
        ci_upper,
        p_value,
        threshold_configured,
        threshold_proportion,
    }
}

fn check_threshold(metric: &str, stats: &MetricStatistics) -> Option<String> {
    let threshold_count = stats.threshold_configured?;
    if stats.total_sessions == 0 {
        return None;
    }
    if stats.changed_sessions > threshold_count {
        return Some(format!(
            "{metric} changed {} > allowed {}",
            stats.changed_sessions, threshold_count
        ));
    }
    if let Some(threshold_prop) = stats.threshold_proportion {
        if stats.ci_lower > threshold_prop {
            return Some(format!(
                "{metric} lower CI {:.3} exceeds threshold proportion {:.3}",
                stats.ci_lower, threshold_prop
            ));
        }
    }
    None
}

fn flush_delta_batch(
    dir: &Path,
    shard_index: usize,
    batch_index: usize,
    buffer: &[SessionDelta],
) -> Result<PathBuf> {
    if buffer.is_empty() {
        return Ok(dir.join(format!("shard{shard_index}-batch{batch_index:04}.jsonl")));
    }
    std::fs::create_dir_all(dir)?;
    let path = dir.join(format!("shard{shard_index}-batch{batch_index:04}.jsonl"));
    let mut file = OpenOptions::new()
        .create(true)
        .write(true)
        .truncate(true)
        .open(&path)
        .with_context(|| format!("create delta batch {}", path.display()))?;
    for delta in buffer {
        serde_json::to_writer(&mut file, delta)?;
        file.write_all(b"\n")?;
    }
    Ok(path)
}

fn fmt_pct(value: f64) -> String {
    if value.is_nan() {
        "n/a".into()
    } else {
        format!("{:.2}%", value * 100.0)
    }
}

fn fmt_ci(lower: f64, upper: f64) -> String {
    if lower == 0.0 && upper == 0.0 {
        "-".into()
    } else {
        format!("{} – {}", fmt_pct(lower), fmt_pct(upper))
    }
}

fn write_markdown(
    report: &BucketReport,
    stats: &StatisticsReport,
    shard: &ShardMetadata,
    thresholds: &Thresholds,
    path: &Path,
) -> Result<()> {
    let mut md = String::new();
    md.push_str("# Evaluation Summary\n\n");
    md.push_str(&format!(
        "- Processed **{}** sessions (shard {}/{}, limit: {})\n",
        shard.processed_sessions,
        shard.shard_index + 1,
        shard.shard_count,
        shard
            .limit
            .map(|l| l.to_string())
            .unwrap_or_else(|| "none".into())
    ));
    md.push_str(&format!(
        "- Skipped **{}** sessions (other shards)\n",
        shard.skipped_sessions
    ));
    md.push_str(&format!(
        "- Observed **{}** behavioural deltas (sampled {})\n\n",
        shard.total_deltas, shard.delta_sample_size
    ));

    md.push_str("## Overall Counts\n\n");
    md.push_str("| metric | count |\n|---|---|\n");
    md.push_str(&format!(
        "| total_sessions | {} |\n",
        report.overall.total_sessions
    ));
    md.push_str(&format!(
        "| verdict_changed | {} |\n",
        report.overall.verdict_changed
    ));
    md.push_str(&format!(
        "| math_status_changed | {} |\n",
        report.overall.math_status_changed
    ));
    md.push_str(&format!(
        "| manual_review_changed | {} |\n\n",
        report.overall.manual_review_changed
    ));

    md.push_str("## Statistical Guardrails\n\n");
    md.push_str("| metric | proportion | 95% CI | threshold | p-value |\n|---|---|---|---|---|\n");
    md.push_str(&format!(
        "| verdict | {} | {} | {} | {} |\n",
        fmt_pct(stats.verdict.proportion),
        fmt_ci(stats.verdict.ci_lower, stats.verdict.ci_upper),
        match thresholds.verdict_max {
            Some(max) => format!(
                "{} ({})",
                max,
                stats
                    .verdict
                    .threshold_proportion
                    .map(fmt_pct)
                    .unwrap_or_else(|| "-".into())
            ),
            None => "n/a".into(),
        },
        stats
            .verdict
            .p_value
            .map(|p| format!("{:.4}", p))
            .unwrap_or_else(|| "n/a".into())
    ));
    md.push_str(&format!(
        "| math_status | {} | {} | {} | {} |\n",
        fmt_pct(stats.math_status.proportion),
        fmt_ci(stats.math_status.ci_lower, stats.math_status.ci_upper),
        match thresholds.math_max {
            Some(max) => format!(
                "{} ({})",
                max,
                stats
                    .math_status
                    .threshold_proportion
                    .map(fmt_pct)
                    .unwrap_or_else(|| "-".into())
            ),
            None => "n/a".into(),
        },
        stats
            .math_status
            .p_value
            .map(|p| format!("{:.4}", p))
            .unwrap_or_else(|| "n/a".into())
    ));
    md.push_str(&format!(
        "| manual_review | {} | {} | {} | {} |\n\n",
        fmt_pct(stats.manual_review.proportion),
        fmt_ci(stats.manual_review.ci_lower, stats.manual_review.ci_upper),
        match thresholds.manual_max {
            Some(max) => format!(
                "{} ({})",
                max,
                stats
                    .manual_review
                    .threshold_proportion
                    .map(fmt_pct)
                    .unwrap_or_else(|| "-".into())
            ),
            None => "n/a".into(),
        },
        stats
            .manual_review
            .p_value
            .map(|p| format!("{:.4}", p))
            .unwrap_or_else(|| "n/a".into())
    ));

    if !report.by_bucket.is_empty() {
        md.push_str("## Domain × Confidence Buckets\n\n");
        md.push_str("| bucket | sessions | verdict Δ | verdict % | math Δ | math % | manual Δ | manual % |\n|---|---|---|---|---|---|---|---|\n");
        for (bucket, metrics) in &report.by_bucket {
            let total = metrics.total_sessions as f64;
            md.push_str(&format!(
                "| {} | {} | {} | {} | {} | {} | {} | {} |\n",
                bucket,
                metrics.total_sessions,
                metrics.verdict_changed,
                if total == 0.0 {
                    "-".into()
                } else {
                    fmt_pct(metrics.verdict_changed as f64 / total)
                },
                metrics.math_status_changed,
                if total == 0.0 {
                    "-".into()
                } else {
                    fmt_pct(metrics.math_status_changed as f64 / total)
                },
                metrics.manual_review_changed,
                if total == 0.0 {
                    "-".into()
                } else {
                    fmt_pct(metrics.manual_review_changed as f64 / total)
                }
            ));
        }
        md.push('\n');
    }

    std::fs::write(path, md)?;
    Ok(())
}

fn write_dashboard(ctx: DashboardContext<'_>, path: &Path) -> Result<()> {
    let DashboardContext {
        report,
        stats,
        shard,
        thresholds,
        delta_sample,
        bootstrap,
        delta_batch_files,
    } = ctx;
    let bucket_rows = report
        .by_bucket
        .iter()
        .map(|(bucket, metrics)| {
            let total = metrics.total_sessions as f64;
            format!(
                "<tr><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td><td>{}</td></tr>",
                bucket,
                metrics.total_sessions,
                metrics.verdict_changed,
                if total == 0.0 { "-".into() } else { fmt_pct(metrics.verdict_changed as f64 / total) },
                metrics.math_status_changed,
                if total == 0.0 { "-".into() } else { fmt_pct(metrics.math_status_changed as f64 / total) },
                metrics.manual_review_changed,
                if total == 0.0 { "-".into() } else { fmt_pct(metrics.manual_review_changed as f64 / total) },
            )
        })
        .collect::<Vec<_>>()
        .join("\n");

    let sample_preview =
        serde_json::to_string_pretty(&delta_sample.iter().take(20).collect::<Vec<_>>())?;

    let threshold_list = format!(
        "<li>Verdict max: {}</li><li>Math max: {}</li><li>Manual max: {}</li>",
        thresholds
            .verdict_max
            .map(|v| v.to_string())
            .unwrap_or_else(|| "n/a".into()),
        thresholds
            .math_max
            .map(|v| v.to_string())
            .unwrap_or_else(|| "n/a".into()),
        thresholds
            .manual_max
            .map(|v| v.to_string())
            .unwrap_or_else(|| "n/a".into())
    );

    let batches_list = if delta_batch_files.is_empty() {
        "<li>No batch files were generated.</li>".to_string()
    } else {
        delta_batch_files
            .iter()
            .map(|path| format!("<li>{}</li>", path))
            .collect::<Vec<_>>()
            .join("")
    };

    let html = format!(
        r#"<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>DeepResearch Evaluation Dashboard</title>
    <style>
        body {{ font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", sans-serif; margin: 2rem; background: #f5f7fb; color: #1c2333; }}
        h1, h2 {{ color: #15203a; }}
        table {{ border-collapse: collapse; width: 100%; margin: 1rem 0; background: #fff; box-shadow: 0 1px 3px rgba(15,23,42,0.08); }}
        th, td {{ border: 1px solid #dde3f0; padding: 0.6rem 0.9rem; text-align: left; }}
        th {{ background: #eef2ff; font-weight: 600; }}
        tbody tr:nth-child(even) {{ background: #f8fafc; }}
        code, pre {{ background: #0f172a; color: #e2e8f0; padding: 0.4rem 0.6rem; border-radius: 6px; display: block; overflow-x: auto; }}
        section {{ margin-bottom: 2.4rem; }}
        .meta {{ display: flex; flex-wrap: wrap; gap: 1.5rem; }}
        .meta div {{ background: #fff; padding: 1rem 1.4rem; border-radius: 8px; box-shadow: 0 1px 2px rgba(15,23,42,0.08); min-width: 220px; }}
        ul {{ background: #fff; padding: 1rem 1.4rem; border-radius: 8px; box-shadow: 0 1px 2px rgba(15,23,42,0.08); }}
        details {{ background: #fff; padding: 1rem 1.4rem; border-radius: 8px; box-shadow: 0 1px 2px rgba(15,23,42,0.08); }}
        summary {{ cursor: pointer; font-weight: 600; }}
    </style>
</head>
<body>
    <h1>DeepResearch Evaluation Dashboard</h1>
    <section class="meta">
        <div>
            <strong>Shard</strong>
            <p>Index {}/{} | Limit: {}</p>
        </div>
        <div>
            <strong>Sessions</strong>
            <p>Processed {} of {} assigned<br/>Skipped {}</p>
        </div>
        <div>
            <strong>Deltas Observed</strong>
            <p>{} total<br/>Sampled {}</p>
        </div>
        <div>
            <strong>Bootstrap</strong>
            <p>{} samples | {:.1}% CI</p>
        </div>
    </section>
    <section>
        <h2>Statistical Guardrails</h2>
        <table>
            <thead>
                <tr>
                    <th>Metric</th>
                    <th>Proportion</th>
                    <th>95% CI</th>
                    <th>Threshold</th>
                    <th>p-value</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>Verdict</td>
                    <td>{}</td>
                    <td>{}</td>
                    <td>{}</td>
                    <td>{}</td>
                </tr>
                <tr>
                    <td>Math Status</td>
                    <td>{}</td>
                    <td>{}</td>
                    <td>{}</td>
                    <td>{}</td>
                </tr>
                <tr>
                    <td>Manual Review</td>
                    <td>{}</td>
                    <td>{}</td>
                    <td>{}</td>
                    <td>{}</td>
                </tr>
            </tbody>
        </table>
    </section>
    <section>
        <h2>Threshold Configuration</h2>
        <ul>
            {}
        </ul>
    </section>
    <section>
        <h2>Bucket Breakdown</h2>
        <table>
            <thead>
                <tr>
                    <th>Bucket</th>
                    <th>Sessions</th>
                    <th>Verdict Δ</th>
                    <th>Verdict %</th>
                    <th>Math Δ</th>
                    <th>Math %</th>
                    <th>Manual Δ</th>
                    <th>Manual %</th>
                </tr>
            </thead>
            <tbody>
                {}
            </tbody>
        </table>
    </section>
    <section>
        <h2>Delta Batches</h2>
        <ul>
            {}
        </ul>
    </section>
    <section>
        <h2>Sampled Deltas (preview)</h2>
        <details>
            <summary>Expand to view up to 20 sampled deltas</summary>
            <pre>{}</pre>
        </details>
    </section>
</body>
</html>
"#,
        shard.shard_index + 1,
        shard.shard_count,
        shard
            .limit
            .map(|l| l.to_string())
            .unwrap_or_else(|| "none".into()),
        shard.processed_sessions,
        shard.assigned_sessions,
        shard.skipped_sessions,
        shard.total_deltas,
        shard.delta_sample_size,
        bootstrap.samples,
        bootstrap.confidence * 100.0,
        fmt_pct(stats.verdict.proportion),
        fmt_ci(stats.verdict.ci_lower, stats.verdict.ci_upper),
        thresholds
            .verdict_max
            .map(|max| {
                format!(
                    "{} ({})",
                    max,
                    stats
                        .verdict
                        .threshold_proportion
                        .map(fmt_pct)
                        .unwrap_or_else(|| "-".into())
                )
            })
            .unwrap_or_else(|| "n/a".into()),
        stats
            .verdict
            .p_value
            .map(|p| format!("{:.4}", p))
            .unwrap_or_else(|| "n/a".into()),
        fmt_pct(stats.math_status.proportion),
        fmt_ci(stats.math_status.ci_lower, stats.math_status.ci_upper),
        thresholds
            .math_max
            .map(|max| {
                format!(
                    "{} ({})",
                    max,
                    stats
                        .math_status
                        .threshold_proportion
                        .map(fmt_pct)
                        .unwrap_or_else(|| "-".into())
                )
            })
            .unwrap_or_else(|| "n/a".into()),
        stats
            .math_status
            .p_value
            .map(|p| format!("{:.4}", p))
            .unwrap_or_else(|| "n/a".into()),
        fmt_pct(stats.manual_review.proportion),
        fmt_ci(stats.manual_review.ci_lower, stats.manual_review.ci_upper),
        thresholds
            .manual_max
            .map(|max| {
                format!(
                    "{} ({})",
                    max,
                    stats
                        .manual_review
                        .threshold_proportion
                        .map(fmt_pct)
                        .unwrap_or_else(|| "-".into())
                )
            })
            .unwrap_or_else(|| "n/a".into()),
        stats
            .manual_review
            .p_value
            .map(|p| format!("{:.4}", p))
            .unwrap_or_else(|| "n/a".into()),
        threshold_list,
        bucket_rows,
        batches_list,
        sample_preview
            .replace('&', "&amp;")
            .replace('<', "&lt;")
            .replace('>', "&gt;")
    );

    std::fs::write(path, html)?;
    Ok(())
}

#[tokio::main]
async fn main() -> Result<()> {
    let mut args = Args::parse();
    if args.shard_count == 0 {
        anyhow::bail!("shard-count must be >= 1");
    }
    if args.shard_index >= args.shard_count {
        anyhow::bail!(
            "shard-index ({}) must be less than shard-count ({})",
            args.shard_index,
            args.shard_count
        );
    }
    args.bootstrap_alpha = clamp_alpha(args.bootstrap_alpha);

    std::fs::create_dir_all(&args.output_dir)?;
    let delta_dir = args.output_dir.join("deltas");
    if args.batch_size > 0 {
        std::fs::create_dir_all(&delta_dir)?;
    }

    let records = load_records(&args.input)?;
    let assigned_sessions = records
        .iter()
        .enumerate()
        .filter(|(idx, _)| *idx % args.shard_count == args.shard_index)
        .count();

    let limit = args.limit.unwrap_or(usize::MAX);

    let mut metrics = AggregateMetrics::default();
    let mut bucket_metrics: BTreeMap<String, AggregateMetrics> = BTreeMap::new();
    let mut verdict_flags = Vec::new();
    let mut math_flags = Vec::new();
    let mut manual_flags = Vec::new();

    let mut delta_sample = Vec::new();
    let mut delta_batches_buffer = Vec::new();
    let mut delta_batches_written = 0usize;
    let mut delta_batch_files = Vec::new();
    let mut total_deltas = 0usize;

    let mut processed_sessions = 0usize;
    let mut skipped_sessions = 0usize;

    for (idx, record) in records.into_iter().enumerate() {
        if idx % args.shard_count != args.shard_index {
            skipped_sessions += 1;
            continue;
        }
        if processed_sessions >= limit {
            break;
        }
        processed_sessions += 1;
        println!(
            "Replaying {} ({}/{})",
            record.session_id,
            processed_sessions,
            assigned_sessions.min(limit)
        );

        let replay = replay_session(&args.replay_cmd, &record.query).await?;
        let verdict_after = replay.verdict;
        let math_status_after = replay
            .math_status
            .clone()
            .unwrap_or_else(|| record.math_status.clone());
        let manual_after = replay
            .manual_review
            .unwrap_or(record.requires_manual_review);

        let verdict_changed = verdict_after.trim() != record.verdict.trim();
        let math_changed = !math_status_after.eq_ignore_ascii_case(&record.math_status);
        let manual_changed = manual_after != record.requires_manual_review;

        verdict_flags.push(verdict_changed);
        math_flags.push(math_changed);
        manual_flags.push(manual_changed);

        metrics.total_sessions += 1;
        if verdict_changed {
            metrics.verdict_changed += 1;
        }
        if math_changed {
            metrics.math_status_changed += 1;
        }
        if manual_changed {
            metrics.manual_review_changed += 1;
        }

        let bucket_key = format!(
            "{}|{}",
            record
                .domain_label
                .clone()
                .unwrap_or_else(|| "unknown".into()),
            record
                .confidence_bucket
                .clone()
                .unwrap_or_else(|| "unknown".into())
        );
        let entry = bucket_metrics.entry(bucket_key).or_default();
        entry.total_sessions += 1;
        if verdict_changed {
            entry.verdict_changed += 1;
        }
        if math_changed {
            entry.math_status_changed += 1;
        }
        if manual_changed {
            entry.manual_review_changed += 1;
        }

        if verdict_changed || math_changed || manual_changed {
            total_deltas += 1;
            let delta = SessionDelta {
                session_id: record.session_id,
                baseline_timestamp: record.timestamp,
                domain_label: record.domain_label,
                confidence_bucket: record.confidence_bucket,
                verdict_before: record.verdict,
                verdict_after,
                math_status_before: record.math_status,
                math_status_after,
                manual_review_before: record.requires_manual_review,
                manual_review_after: manual_after,
                verdict_changed,
                math_changed,
                manual_review_changed: manual_changed,
                timestamp: Utc::now(),
            };

            if args.delta_sample_limit > 0 {
                if delta_sample.len() < args.delta_sample_limit {
                    delta_sample.push(delta.clone());
                } else {
                    let mut rng = rand::thread_rng();
                    let j = rng.gen_range(0..total_deltas);
                    if j < args.delta_sample_limit {
                        delta_sample[j] = delta.clone();
                    }
                }
            }

            if args.batch_size > 0 {
                delta_batches_buffer.push(delta);
                if delta_batches_buffer.len() >= args.batch_size {
                    let path = flush_delta_batch(
                        &delta_dir,
                        args.shard_index,
                        delta_batches_written,
                        &delta_batches_buffer,
                    )?;
                    delta_batch_files.push(path.display().to_string());
                    delta_batches_written += 1;
                    delta_batches_buffer.clear();
                }
            }
        }
    }

    if args.batch_size > 0 && !delta_batches_buffer.is_empty() {
        let path = flush_delta_batch(
            &delta_dir,
            args.shard_index,
            delta_batches_written,
            &delta_batches_buffer,
        )?;
        delta_batch_files.push(path.display().to_string());
        delta_batches_written += 1;
    }

    let report = BucketReport {
        overall: metrics,
        by_bucket: bucket_metrics,
    };

    let statistics = StatisticsReport {
        verdict: compute_metric_statistics(
            &verdict_flags,
            args.max_verdict_delta,
            args.bootstrap_samples,
            args.bootstrap_alpha,
        ),
        math_status: compute_metric_statistics(
            &math_flags,
            args.max_math_delta,
            args.bootstrap_samples,
            args.bootstrap_alpha,
        ),
        manual_review: compute_metric_statistics(
            &manual_flags,
            args.max_manual_delta,
            args.bootstrap_samples,
            args.bootstrap_alpha,
        ),
    };

    let thresholds = Thresholds {
        verdict_max: (args.max_verdict_delta != usize::MAX).then_some(args.max_verdict_delta),
        math_max: (args.max_math_delta != usize::MAX).then_some(args.max_math_delta),
        manual_max: (args.max_manual_delta != usize::MAX).then_some(args.max_manual_delta),
    };

    let shard_meta = ShardMetadata {
        shard_index: args.shard_index,
        shard_count: args.shard_count,
        assigned_sessions,
        processed_sessions,
        skipped_sessions,
        limit: args.limit,
        delta_batches_written,
        delta_sample_size: delta_sample.len(),
        total_deltas,
    };

    let bootstrap = BootstrapConfig {
        samples: args.bootstrap_samples,
        alpha: args.bootstrap_alpha,
        confidence: 1.0 - args.bootstrap_alpha,
    };

    let report_json = args.output_dir.join("report.json");
    let harness_report = HarnessReport {
        summary: report.clone(),
        statistics: statistics.clone(),
        bootstrap: bootstrap.clone(),
        thresholds: thresholds.clone(),
        shard: shard_meta.clone(),
        delta_sample_limit: args.delta_sample_limit,
        delta_sample: delta_sample.clone(),
        delta_batch_files: delta_batch_files.clone(),
    };

    serde_json::to_writer_pretty(File::create(&report_json)?, &harness_report)?;

    let report_md = args.output_dir.join("report.md");
    write_markdown(&report, &statistics, &shard_meta, &thresholds, &report_md)?;

    let dashboard_html = args.output_dir.join("dashboard.html");
    write_dashboard(
        DashboardContext {
            report: &report,
            stats: &statistics,
            shard: &shard_meta,
            thresholds: &thresholds,
            delta_sample: &delta_sample,
            bootstrap: &bootstrap,
            delta_batch_files: &delta_batch_files,
        },
        &dashboard_html,
    )?;

    let mut violations = Vec::new();
    if let Some(reason) = check_threshold("verdict", &statistics.verdict) {
        violations.push(reason);
    }
    if let Some(reason) = check_threshold("math_status", &statistics.math_status) {
        violations.push(reason);
    }
    if let Some(reason) = check_threshold("manual_review", &statistics.manual_review) {
        violations.push(reason);
    }

    if !violations.is_empty() {
        anyhow::bail!("evaluation thresholds exceeded: {}", violations.join("; "));
    }

    println!("Report written to {}", report_json.display());
    println!("Dashboard written to {}", dashboard_html.display());
    Ok(())
}
